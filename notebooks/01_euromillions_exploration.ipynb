{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Euromillions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des librairies\n",
    "import pandas as pd\n",
    "import csv\n",
    "import os\n",
    "from IPython.display import display\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "from pathlib import Path\n",
    "\n",
    "# Variables utiles\n",
    "dir_raw = Path(r\"C:\\Users\\hbern\\Downloads\\notebooks\\euromillions-git\\data\\raw\")\n",
    "dir_processed = Path(r\"C:\\Users\\hbern\\Downloads\\notebooks\\euromillions-git\\data\\processed\")\n",
    "fdj_url = \"https://www.sto.api.fdj.fr/anonymous/service-draw-info/v3/documentations\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Import des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des fichiers\n",
    "files = {\n",
    "    \"euromillions\": \"1a2b3c4d-9876-4562-b3fc-2c963f66afa8\",\n",
    "    \"euromillions_2\": \"1a2b3c4d-9876-4562-b3fc-2c963f66afa9\",\n",
    "    \"euromillions_3\": \"1a2b3c4d-9876-4562-b3fc-2c963f66afb6\",\n",
    "    \"euromillions_4\": \"1a2b3c4d-9876-4562-b3fc-2c963f66afc6\", \n",
    "    \"euromillions_201902\": \"1a2b3c4d-9876-4562-b3fc-2c963f66afd6\",  \n",
    "    \"euromillions_202002\": \"1a2b3c4d-9876-4562-b3fc-2c963f66afe6\"\n",
    "}\n",
    "\n",
    "def download_and_unzip(file_name: str, uuid: str, fdj_url: str, dir_raw: str | Path):\n",
    "    dir_raw = Path(dir_raw)\n",
    "    dir_raw.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    url = f\"{fdj_url}/{uuid}\"\n",
    "    print(f\"üì• T√©l√©chargement de {url}\")\n",
    "\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()\n",
    "\n",
    "    with zipfile.ZipFile(io.BytesIO(r.content)) as z:\n",
    "        # on prend le premier CSV trouv√© dans le ZIP\n",
    "        csv_names = [n for n in z.namelist() if n.lower().endswith(\".csv\")]\n",
    "        if not csv_names:\n",
    "            raise ValueError(f\"Aucun CSV dans l'archive {uuid}\")\n",
    "\n",
    "        interne = csv_names[0]\n",
    "        z.extract(interne, dir_raw)\n",
    "\n",
    "    source = dir_raw / interne\n",
    "    raw = dir_raw / f\"{file_name}.csv\"\n",
    "\n",
    "    source.rename(raw)\n",
    "    print(f\"‚úÖ {raw.name} cr√©√©\")\n",
    "\n",
    "for file_name, uuid in files.items():\n",
    "    fp = dir_raw / f\"{file_name}.csv\"\n",
    "\n",
    "    # cas sp√©cial : toujours r√©importer le dernier fichier\n",
    "    if file_name == \"euromillions_202002\":\n",
    "        print(f\"‚ôªÔ∏è R√©import forc√© de {fp.name}\")\n",
    "        download_and_unzip(file_name, uuid, fdj_url, dir_raw)\n",
    "        continue\n",
    "\n",
    "    # comportement normal pour les autres\n",
    "    if fp.exists():\n",
    "        print(f\"‚è≠Ô∏è {fp.name} existe d√©j√†\")\n",
    "        continue\n",
    "\n",
    "    print(f\"üìÇ {fp.name} absent ‚Üí import\")\n",
    "    download_and_unzip(file_name, uuid, fdj_url, dir_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Fonction de lecture des fichiers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file: str, dir_raw: str) -> pd.DataFrame:\n",
    "    \"\"\"Lit un fichier CSV et renvoie un DataFrame pandas.\"\"\"\n",
    "\n",
    "    dir_raw = Path(dir_raw)\n",
    "\n",
    "    file_path = dir_raw / file  \n",
    "    \n",
    "    encoding_type = \"utf-8-sig\"\n",
    "\n",
    "    if file in (\"euromillions_4.csv\", \"euromillions_201902.csv\"):\n",
    "        encoding_type = \"cp1252\"\n",
    "    \n",
    "    df = pd.read_csv(\n",
    "        file_path,\n",
    "        index_col=False,\n",
    "        engine=\"python\",\n",
    "        sep=None,\n",
    "        encoding=encoding_type,\n",
    "        quotechar='\"',\n",
    "        escapechar='\\\\',\n",
    "        skip_blank_lines=True,\n",
    "        on_bad_lines=\"skip\"\n",
    "    )    \n",
    "\n",
    "    # Remet les dates de tirage par ordre croissant, sauf le fichier euromillions_4 o√π elles le sont d√©j√†\n",
    "    if file != \"euromillions_4.csv\":\n",
    "        df = df.iloc[::-1].reset_index(drop=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des colonnes √† supprimer dans les fichiers\n",
    "\n",
    "# fichier 1\n",
    "cols_to_drop = ['date_de_forclusion', 'nombre_de_gagnant_au_rang2_en_france', 'nombre_de_gagnant_au_rang2_en_europe', 'rapport_du_rang2',\n",
    "       'nombre_de_gagnant_au_rang3_en_france', 'nombre_de_gagnant_au_rang3_en_europe', 'rapport_du_rang3', 'nombre_de_gagnant_au_rang4_en_france', 'nombre_de_gagnant_au_rang4_en_europe', 'rapport_du_rang4',\n",
    "       'nombre_de_gagnant_au_rang5_en_france', 'nombre_de_gagnant_au_rang5_en_europe', 'rapport_du_rang5', 'nombre_de_gagnant_au_rang6_en_france', 'nombre_de_gagnant_au_rang6_en_europe', 'rapport_du_rang6',\n",
    "       'nombre_de_gagnant_au_rang7_en_france', 'nombre_de_gagnant_au_rang7_en_europe', 'rapport_du_rang7', 'nombre_de_gagnant_au_rang8_en_france', 'nombre_de_gagnant_au_rang8_en_europe', 'rapport_du_rang8',\n",
    "       'nombre_de_gagnant_au_rang9_en_france', 'nombre_de_gagnant_au_rang9_en_europe', 'rapport_du_rang9', 'nombre_de_gagnant_au_rang10_en_france', 'nombre_de_gagnant_au_rang10_en_europe', 'rapport_du_rang10',\n",
    "       'nombre_de_gagnant_au_rang11_en_france', 'nombre_de_gagnant_au_rang11_en_europe', 'rapport_du_rang11', 'nombre_de_gagnant_au_rang12_en_france', 'nombre_de_gagnant_au_rang12_en_europe', 'rapport_du_rang12',\n",
    "       'numero_jokerplus', 'devise', 'Unnamed: 51']\n",
    "\n",
    "# fichier 2\n",
    "cols_to_drop += ['nombre_de_gagnant_au_rang13_en_france', 'nombre_de_gagnant_au_rang13_en_europe', 'rapport_du_rang13', 'Unnamed: 54']\n",
    "\n",
    "# fichier 3\n",
    "cols_to_drop += ['numero_My_Million']\n",
    "\n",
    "# fichier 4\n",
    "cols_to_drop += ['num√©ro_de_tirage_dans_le_cycle', 'nombre_de_gagnant_au_rang2_Euro_Millions_en_france', 'nombre_de_gagnant_au_rang2_Euro_Millions_en_europe', 'rapport_du_rang2_Euro_Millions', 'nombre_de_gagnant_au_rang3_Euro_Millions_en_france', 'nombre_de_gagnant_au_rang3_Euro_Millions_en_europe', 'rapport_du_rang3_Euro_Millions', 'nombre_de_gagnant_au_rang4_Euro_Millions_en_france', 'nombre_de_gagnant_au_rang4_Euro_Millions_en_europe', 'rapport_du_rang4_Euro_Millions', 'nombre_de_gagnant_au_rang5_Euro_Millions_en_france', 'nombre_de_gagnant_au_rang5_Euro_Millions_en_europe', 'rapport_du_rang5_Euro_Millions', 'nombre_de_gagnant_au_rang6_Euro_Millions_en_france', 'nombre_de_gagnant_au_rang6_Euro_Millions_en_europe', 'rapport_du_rang6_Euro_Millions', 'nombre_de_gagnant_au_rang7_Euro_Millions_en_france', 'nombre_de_gagnant_au_rang7_Euro_Millions_en_europe', 'rapport_du_rang7_Euro_Millions', 'nombre_de_gagnant_au_rang8_Euro_Millions_en_france', 'nombre_de_gagnant_au_rang8_Euro_Millions_en_europe', 'rapport_du_rang8_Euro_Millions', 'nombre_de_gagnant_au_rang9_Euro_Millions_en_france', 'nombre_de_gagnant_au_rang9_Euro_Millions_en_europe', 'rapport_du_rang9_Euro_Millions', 'nombre_de_gagnant_au_rang10_Euro_Millions_en_france', 'nombre_de_gagnant_au_rang10_Euro_Millions_en_europe', 'rapport_du_rang10_Euro_Millions', 'nombre_de_gagnant_au_rang11_Euro_Millions_en_france', 'nombre_de_gagnant_au_rang11_Euro_Millions_en_europe', 'rapport_du_rang11_Euro_Millions', 'nombre_de_gagnant_au_rang12_Euro_Millions_en_france', 'nombre_de_gagnant_au_rang12_Euro_Millions_en_europe', 'rapport_du_rang12_Euro_Millions', 'nombre_de_gagnant_au_rang13_Euro_Millions_en_france', 'nombre_de_gagnant_au_rang13_Euro_Millions_en_europe', 'rapport_du_rang13_Euro_Millions', 'nombre_de_gagnant_au_rang1_Etoile+', 'rapport_du_rang1_Etoile+', 'nombre_de_gagnant_au_rang2_Etoile+', 'rapport_du_rang2_Etoile+', 'nombre_de_gagnant_au_rang3_Etoile+', 'rapport_du_rang3_Etoile+', 'nombre_de_gagnant_au_rang4_Etoile+', 'rapport_du_rang4_Etoile+',\n",
    "       'nombre_de_gagnant_au_rang5_Etoile+', 'rapport_du_rang5_Etoile+', 'nombre_de_gagnant_au_rang6_Etoile+', 'rapport_du_rang6_Etoile+', 'nombre_de_gagnant_au_rang7_Etoile+', 'rapport_du_rang7_Etoile+', 'nombre_de_gagnant_au_rang8_Etoile+', 'rapport_du_rang8_Etoile+', 'nombre_de_gagnant_au_rang9_Etoile+', 'rapport_du_rang9_Etoile+', 'nombre_de_gagnant_au_rang10_Etoile+', 'rapport_du_rang10_Etoile+', 'numero_Tirage_Exceptionnel_Euro_Millions']\n",
    "\n",
    "# fichier 201902\n",
    "cols_to_drop += ['Unnamed: 75']\n",
    "\n",
    "# fichier 202002\n",
    "cols_to_drop += ['numero_Tirage_Exceptionnel_Euro_Million']\n",
    "\n",
    "# print(cols_to_drop)\n",
    "# print(\"Nombre de colonnes √† supprimer : \" + str(len(cols_to_drop)))\n",
    "# D√©doublonne pour √™tre s√ªr \n",
    "# cols_to_drop = list(set(cols_to_drop))\n",
    "# print(\"Nombre de colonnes √† supprimer (d√©doublonn√©e) : \" + str(len(cols_to_drop)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 1. Fichier euromillions.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "- 13/02/2004 au 06/05/2011\n",
    "- Tirages 1 √† 378 (indices 0 √† 377)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = read_csv(\"euromillions.csv\", dir_raw)\n",
    "\n",
    "# Supprime les colonnes inutiles \n",
    "df1 = df1.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "df1.head(df1.shape[0]) # 378,15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## 2. Fichier euromillions_2.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "- 10/05/2011 au 31/01/2014\n",
    "- Tirages 379 √† 664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = read_csv(\"euromillions_2.csv\", dir_raw)\n",
    "\n",
    "# Supprime les colonnes inutiles \n",
    "df2 = df2.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "df2.head(df2.shape[0]) # (286, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## 3. Fichier euromillions_3.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- 04/02/2014 au 23/09/2016\n",
    "- Tirages 665 √† 940\n",
    "- Introduction num√©ro My Million"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = read_csv(\"euromillions_3.csv\", dir_raw)\n",
    "\n",
    "# Supprime les colonnes inutiles \n",
    "df3 = df3.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "# Corrige en 23/09/2016 la date de la derni√®re ligne :\n",
    "# 275 \t2016077 \tVENDREDI \t23/09/16 \t\n",
    "df3.loc[275, \"date_de_tirage\"] = \"23/09/2016\"\n",
    "\n",
    "df3.head(df3.shape[0]) # (276, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "## 4. Fichier euromillions_4.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "- 27/09/2016 au 26/02/2019\n",
    "- Tirages 941 √† 1290 \n",
    "- Introduction Etoile+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = read_csv(\"euromillions_4.csv\", dir_raw)\n",
    "\n",
    "# Supprime les colonnes inutiles \n",
    "df4 = df4.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "df4.head(df4.shape[0]) # (253, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "## 5. Fichier euromillions_201902.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "- 01/03/2019 au 31/01/2020\n",
    "- Tirages 1194 √† 1290  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = read_csv(\"euromillions_201902.csv\", dir_raw)\n",
    "\n",
    "# Supprime les colonnes inutiles \n",
    "df5 = df5.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "df5.head(df5.shape[0]) # (97, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "## 6. Fichier euromillions_202002.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "- Depuis le 04/02/2020\n",
    "- Depuis tirage 1291   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_and_unzip(url: str, dir_raw: str | Path):\n",
    "    \"\"\"\n",
    "        T√©l√©charge un fichier ZIP depuis une URL et le d√©compresse dans le dossier indiqu√©.\n",
    "    \"\"\"\n",
    "    dir_raw = Path(dir_raw)\n",
    "    dir_raw.mkdir(parents=True, exist_ok=True)  # cr√©e le dossier si besoin\n",
    "\n",
    "    print(f\"üì• T√©l√©chargement de {url} ...\")\n",
    "    r = requests.get(url)\n",
    "    r.raise_for_status()  # l√®ve une erreur si le t√©l√©chargement √©choue\n",
    "\n",
    "    print(\"üóúÔ∏è D√©compression...\")\n",
    "    with zipfile.ZipFile(io.BytesIO(r.content)) as z:\n",
    "        z.extractall(dir_raw)\n",
    "\n",
    "    print(f\"‚úÖ Fichiers extraits dans : {dir_raw.resolve()}\")\n",
    "\n",
    "download_and_unzip(\"https://www.sto.api.fdj.fr/anonymous/service-draw-info/v3/documentations/1a2b3c4d-9876-4562-b3fc-2c963f66afe6\", dir_raw)\n",
    "\n",
    "df6 = read_csv(\"euromillions_202002.csv\", dir_raw)\n",
    "\n",
    "# Supprime les colonnes inutiles \n",
    "df6 = df6.drop(columns=cols_to_drop, errors=\"ignore\")\n",
    "\n",
    "df6.head(df6.shape[0]) # (XXX, 15)\n",
    "\n",
    "print(f\"Date du dernier tirage : {df6[\"date_de_tirage\"].iloc[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes_nouvelles = [\"annee_numero_tirage\", \"jour_tirage\", \"date_tirage\", \n",
    "               \"boule_1\", \"boule_2\", \"boule_3\", \"boule_4\", \"boule_5\",\n",
    "               \"etoile_1\", \"etoile_2\",\n",
    "               \"boules_croissant\", \"etoiles_croissant\",\n",
    "               \"nb_gagnants_r1_fr\", \"nb_gagnants_r1_eu\", \"rapport_r1\"\n",
    "              ]\n",
    "\n",
    "# Liste des DataFrames\n",
    "dataframes = [df1, df2, df3, df4, df5, df6]\n",
    "\n",
    "# Boucle sur la liste\n",
    "for df in dataframes:\n",
    "    df.columns = colonnes_nouvelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat√©nation\n",
    "df = pd.concat([df1, df2, df3, df4, df5, df6], ignore_index=True)\n",
    "\n",
    "df.head(df.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Etat du dataframe\n",
    "df.dtypes\n",
    "df.info()\n",
    "\n",
    "df.isna()\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# jour tirage = 'V' ou 'M' \n",
    "df[\"jour_tirage\"] = df[\"jour_tirage\"].astype(str).str[0]\n",
    "\n",
    "# supprime les '-' en d√©but et fin \n",
    "df[\"boules_croissant\"] = df[\"boules_croissant\"].astype(str).str.strip(\"-\")\n",
    "df[\"etoiles_croissant\"] = df[\"etoiles_croissant\"].astype(str).str.strip(\"-\")\n",
    "\n",
    "df.head(df.shape[0]) # 1893 rows √ó 15 columns\n",
    "\n",
    "# D√©marre l'index √† 1 au lieu de 0 = correspond ainsi au num√©ro de tirage depuis le d√©but\n",
    "df = df.reset_index(drop=True)\n",
    "df.index += 1\n",
    "\n",
    "# Conversion de la colonne 'date' en datetime\n",
    "df[\"date_tirage\"] = pd.to_datetime(df[\"date_tirage\"], dayfirst=True, errors=\"coerce\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export du dataframe global\n",
    "global_file_path = os.path.join(dir_processed, \"global.csv\")\n",
    "\n",
    "# on supprime le fichier 'csv/global.csv' sil existe \n",
    "if os.path.exists(global_file_path):\n",
    "    os.remove(global_file_path)\n",
    "\n",
    "df_export = df.copy()\n",
    "df_export[\"date_tirage\"] = df_export[\"date_tirage\"].dt.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "df_export.to_csv(global_file_path, index=False, encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "## Nettoyage et processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------------------------------------------------\n",
    "# 1) nettoyage\n",
    "# -----------------------------------------------------------------------\n",
    "\n",
    "# Normalisation des types\n",
    "# - Conversion des colonnes num√©riques mal typ√©es\n",
    "for col in [\"etoile_2\", \"rapport_r1\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "# Conversion de la date\n",
    "if \"date_tirage\" in df.columns:\n",
    "    df[\"date_tirage\"] = pd.to_datetime(df[\"date_tirage\"], errors=\"coerce\", format=\"%Y%m%d\").fillna(\n",
    "        pd.to_datetime(df[\"date_tirage\"], errors=\"coerce\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "## Affichage final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "    df[\"date_tirage\"] = df[\"date_tirage\"].dt.strftime(\"%d/%m/%Y\")\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
